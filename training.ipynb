{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.logic.base.calculus import generate_models\n",
    "from src.logic.base.syntax import Exists, Forall, Formula, Predicate, Sort, Variable\n",
    "from src.logic.base.tableau import Tableau\n",
    "from src.query_environment.environment import AxiomsBase, AxiomUtils\n",
    "\n",
    "import rich\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "import functools\n",
    "import json\n",
    "import operator as op\n",
    "from typing import Dict, List, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data.json\", \"r\") as fp:\n",
    "    raw_data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sorts:\n",
    "    individual: Sort = Sort(\"individual\")\n",
    "    verb: Sort = Sort(\"verb\")\n",
    "    event: Sort = Sort(\"event\")\n",
    "    adjective: Sort = Sort(\"adjective\")\n",
    "\n",
    "\n",
    "class Predicates:\n",
    "    subject = Predicate(\"subject\", 2, [Sorts.event, Sorts.individual])\n",
    "    verb = Predicate(\"verb\", 2, [Sorts.event, Sorts.verb])\n",
    "    object_ = Predicate(\"object\", 2, [Sorts.event, Sorts.individual])\n",
    "    adjective = Predicate(\"adjective\", 2, [Sorts.adjective, Sorts.individual])\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Noun:\n",
    "    name: str\n",
    "    referent: Optional[str]\n",
    "    is_reference: bool\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self.name = self.name.lower()\n",
    "        if self.referent:\n",
    "            self.referent = self.referent.lower()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.name} ({self.referent})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Axioms(AxiomsBase):\n",
    "    @staticmethod\n",
    "    @AxiomUtils.only_one_kind_per_event(Predicates.subject)\n",
    "    def axiom_only_one_subject(tableau: Tableau) -> Optional[Tableau]:\n",
    "        \"\"\"Only only subject per event\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    @AxiomUtils.only_one_kind_per_event(Predicates.object_)\n",
    "    def axiom_only_one_object(tableau: Tableau) -> Optional[Tableau]:\n",
    "        \"\"\"Only only object per event\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    @AxiomUtils.only_one_kind_per_event(Predicates.verb)\n",
    "    def axiom_only_one_verb(tableau: Tableau) -> Optional[Tableau]:\n",
    "        \"\"\"Only only verb per event\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Sentence:\n",
    "    \"\"\"This class is used for sentence initial annotation to help with translation to logic.\"\"\"\n",
    "    sentence: str\n",
    "    subject: Noun\n",
    "    verb: str\n",
    "    object_: Optional[Noun]\n",
    "    adjectives: List[Tuple[str, str]]\n",
    "    is_negated: bool\n",
    "    is_always: bool\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self.sentence = self.sentence.lower()\n",
    "        self.verb = self.verb.lower()\n",
    "        self.adjectives = [(first.lower(), second.lower()) for first, second in self.adjectives]\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, sentence_dict: Dict[str, any]) -> \"Sentence\":\n",
    "        \"\"\"Create and return a new sentence from a dictionary\"\"\"\n",
    "        dict_ = deepcopy(sentence_dict)\n",
    "        dict_[\"subject\"] = Noun(**dict_[\"subject\"])\n",
    "        # Create proper noun objects\n",
    "        if dict_.get(\"object_\"):\n",
    "            dict_[\"object_\"] = Noun(**dict_[\"object_\"])\n",
    "        # Make sure adjectives have the correct tuple type\n",
    "        adjectives = []\n",
    "        for adjective, noun in dict_[\"adjectives\"]:\n",
    "            adjectives.append((adjective, noun))\n",
    "        dict_[\"adjectives\"] = adjectives\n",
    "        # Create and return the new sentence object\n",
    "        return cls(**dict_)\n",
    "\n",
    "    def get_tableaus(self, parent: Optional[Tableau] = None) -> List[Tableau]:\n",
    "        \"\"\"Create all possible logical formulas from the sentence based on different readings.\"\"\"\n",
    "        entities = []\n",
    "\n",
    "        # Find verb\n",
    "        v_const = Sorts.verb.make_constant(self.verb)\n",
    "        entities.append(v_const)\n",
    "        verb = lambda e: Predicates.verb(e, v_const)\n",
    "\n",
    "        # Find subject\n",
    "        if self.subject.is_reference:\n",
    "            s = Variable(Sorts.individual, self.subject.name)\n",
    "            subject = lambda e: Exists(lambda v: Predicates.subject(e, v), variable=s)\n",
    "        else:\n",
    "            s_const = Sorts.individual.make_constant(self.subject.name)\n",
    "            entities.append(s_const)\n",
    "            subject = lambda e: Predicates.subject(e, s_const)\n",
    "\n",
    "        # Find object\n",
    "        object_ = None\n",
    "        if self.object_:\n",
    "            if self.object_.is_reference:\n",
    "                o = Variable(Sorts.individual)\n",
    "                object_ = lambda e: Exists(\n",
    "                    lambda v: Predicates.object_(e, v), variable=o\n",
    "                )\n",
    "            else:\n",
    "                o_const = Sorts.individual.make_constant(self.object_.name)\n",
    "                entities.append(o_const)\n",
    "                object_ = lambda e: Predicates.object_(\n",
    "                    e, o_const\n",
    "                )\n",
    "\n",
    "        # Find adjectives\n",
    "        adj_forms: List[Formula] = []\n",
    "        for adjective, noun in self.adjectives:\n",
    "            adj_const = Sorts.adjective.make_constant(adjective)\n",
    "            entities.append(adj_const)\n",
    "            noun_const = Sorts.individual.make_constant(noun)\n",
    "            entities.append(noun_const)\n",
    "            adj_forms.append(Predicates.adjective(adj_const, noun_const))\n",
    "        adj_form = None\n",
    "        if adj_forms:\n",
    "            adj_form = functools.reduce(op.and_, adj_forms)\n",
    "\n",
    "        # Collect formulas\n",
    "        formulas = []\n",
    "        # Handle the case where the sentence is negated\n",
    "        if self.is_negated:\n",
    "            formulas.extend(self._get_negated_readings(subject, verb, object_, adj_form))\n",
    "        else:\n",
    "            # Handle the case where the sentence is not negated and has the modifier always\n",
    "            if self.is_always:\n",
    "                formulas.extend(self._get_always_readings(subject, verb, object_, adj_form))\n",
    "            # Handle the case where the sentence is not negated and doesn't have the modifier always\n",
    "            else:\n",
    "                # In this case, there is only one simple reading of Ee. subject(e) & object(e) & adjectives\n",
    "                formulas.extend(self._get_simple_readings(subject, verb, object_, adj_form))\n",
    "\n",
    "        # Create a tableau for each formula / reading\n",
    "        tableaus: List[Tableau] = [Tableau([formula], entities) for formula in formulas]\n",
    "        # If a parent is provided, use the merge function to assert the uniqueness properties\n",
    "        if parent:\n",
    "            tableaus = [tableau.merge(parent=parent) for tableau in tableaus]\n",
    "        # Return the created tableaus\n",
    "        return tableaus\n",
    "\n",
    "    def _get_negated_readings(self, subject, verb, object_, adjectives: Optional[Formula]) -> List[Formula]:\n",
    "        formulas = []\n",
    "        if self.is_always:\n",
    "            raise NotImplementedError(\"Cannot process sentences with both always and negation.\")\n",
    "        # Technically, the powerset of the components of the sentence should be used,\n",
    "        # but this is sufficient for the time being.\n",
    "        # First case: negated subject formula\n",
    "        formulas.append(Exists(lambda e: ~subject(e) & verb(e) & object_(e) & adjectives))\n",
    "        # Second case: negated object formula\n",
    "        if object_:\n",
    "            formulas.append(Exists(lambda e: ~object_(e) & subject(e) & verb(e) & adjectives))\n",
    "        # Third case: negated verg\n",
    "            formulas.append(Exists(lambda e: ~verb(e) & subject(e) & object_(e) & adjectives))\n",
    "        # Fourth case: negated event\n",
    "        formulas.append(~Exists(lambda e: subject(e) & verb(e) & object_(e) & adjectives))\n",
    "        return formulas\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_always_readings(subject, verb, object_, adjectives: Optional[Formula]) -> List[Formula]:\n",
    "        formulas: List[Formula] = []\n",
    "        if not object_:\n",
    "            raise ValueError(\"No object found in an always statement.\")\n",
    "        # First formula is subject -> (object & adjectives & verb)\n",
    "        first_formula: Predicate = lambda e: object_(e) & verb(e)\n",
    "        if adjectives:\n",
    "            first_formula1 = lambda e: first_formula(e) & adjectives\n",
    "        else:\n",
    "            first_formula1 = first_formula\n",
    "        formulas.append(\n",
    "    Forall(lambda e: subject(e) >> first_formula1(e))\n",
    "        )\n",
    "        # Second formula is object -> (subject & adjectives & verb)\n",
    "        second_formula: Predicate = lambda e: subject(e) & verb(e)\n",
    "        if adjectives:\n",
    "            second_formula1 = lambda e: second_formula(e) & adjectives\n",
    "        else:\n",
    "            second_formula1 = second_formula\n",
    "        formulas.append(Forall(lambda e: object_(e) >> second_formula1(e)))\n",
    "        # Third formula is verb -> (subject & adjectives & object)\n",
    "        third_formula: Predicate = lambda e: subject(e) & object_(e)\n",
    "        if adjectives:\n",
    "            third_formula1 = lambda e: third_formula(e) & adjectives\n",
    "        else:\n",
    "            third_formula1 = third_formula\n",
    "\n",
    "        formulas.append(Forall(lambda e: verb(e) >> third_formula1(e)))\n",
    "        return formulas\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_simple_readings(subject: Predicate, verb: Predicate, object_: Optional[Predicate], adjectives: Optional[Formula]) -> List[Formula]:\n",
    "        formula: Predicate = lambda e: verb(e) & subject(e)\n",
    "        if object_:\n",
    "            formula1 = lambda e: formula(e) & object_(e)\n",
    "        else:\n",
    "            formula1 = formula\n",
    "        \n",
    "        if adjectives:\n",
    "            formula2 = lambda e: formula1(e) & adjectives\n",
    "        else:\n",
    "            formula2 = formula1\n",
    "        return [Exists(formula2, Sorts.event)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_formulas(*formulas: Formula, sort: bool = True) -> None:\n",
    "            if sort:\n",
    "                formulas = sorted(map(str, formulas), key=lambda x: (len(x), x))\n",
    "            print(\"\", *formulas, sep=\"\\n  - \")\n",
    "            print()\n",
    "\n",
    "@dataclass\n",
    "class ModelTreeNode:\n",
    "    reading_model: Tableau\n",
    "    previous_sentence_reading: Optional[\"DialogTreeNode\"] = None\n",
    "    next_sentence_readings: List[\"DialogTreeNode\"] = field(default_factory=list)\n",
    "\n",
    "    def extend_tree(self, *sentences: Sentence) -> None:\n",
    "        if not sentences:\n",
    "            return\n",
    "        next_sentence, *rest_sentences = sentences\n",
    "        for reading in next_sentence.get_tableaus():\n",
    "            node = DialogTreeNode(next_sentence, reading, parent_reading_model=self)\n",
    "            node.extend_tree(*rest_sentences)\n",
    "            self.next_sentence_readings.append(node)\n",
    "    \n",
    "    @classmethod\n",
    "    def create_tree(cls, *sentences: Sentence) -> \"ModelTreeNode\":\n",
    "        node = ModelTreeNode(Tableau())\n",
    "        node.extend_tree(*sentences)\n",
    "        return node\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DialogTreeNode:\n",
    "    sentence: Sentence\n",
    "    sentence_reading: Tableau\n",
    "    parent_reading_model: ModelTreeNode\n",
    "    models: List[ModelTreeNode] = field(default_factory=list)\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        if not self.models:\n",
    "            self._gen_models()\n",
    "\n",
    "    def _gen_models(self) -> None:\n",
    "        extended_tableau = Tableau.merge(self.sentence_reading, parent=self.parent_reading_model.reading_model)\n",
    "        for model in generate_models(extended_tableau, axioms=Axioms.get_axioms()):\n",
    "            self.models.append(ModelTreeNode(model, self))\n",
    "\n",
    "    def extend_tree(self, *sentences: Sentence) -> None:\n",
    "        for model in self.models:\n",
    "            model.extend_tree(*sentences)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Dialog:\n",
    "    sentences: List[Sentence]\n",
    "    model_root: ModelTreeNode = field(init=False)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __item__(self, depth: int) -> None:\n",
    "        return self.get_models_at_depth(depth)\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "         self.model_root = ModelTreeNode.create_tree(*self.sentences)\n",
    "\n",
    "    def get_models_at_depth(self, sentence_depth: int) -> List[ModelTreeNode]:\n",
    "        \"\"\"Get all the models of the dialog at given sentence depth\"\"\"\n",
    "        if sentence_depth >= len(self):\n",
    "            raise KeyError(f\"Cannot get model at depth {sentence_depth} from a dialog of depth {len(self)}\")\n",
    "        current_models = [self.model_root]\n",
    "        for _ in range(sentence_depth+1):\n",
    "            next_models = []\n",
    "            for model in current_models:\n",
    "                for reading in model.next_sentence_readings:\n",
    "                    next_models.extend(reading.models)\n",
    "            current_models = next_models\n",
    "        return current_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogs: List[Dialog] = []\n",
    "for raw_dialog in raw_data.get(\"annotations\"):\n",
    "    dialog_sentences = []\n",
    "    for sentence in raw_dialog:\n",
    "        dialog_sentences.append(Sentence.from_dict(sentence))\n",
    "    dialogs.append(Dialog(dialog_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models = dialogs[0].get_models_at_depth(len(dialogs[0]) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_formulas(*final_models[0].reading_model.branch_literals, sort=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
